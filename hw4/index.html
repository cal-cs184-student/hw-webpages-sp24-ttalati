<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CS 184 Homework 4, 
Tanush Talati</title>
    <style>
	.left {
		text-align: left;
	}
        .caption {
            text-align: center;
            font-style: italic;
        }
        .im-container { 
            justify-content: space-between; 
            margin-bottom: -10px;
            flex-wrap: wrap;
            text-align: center;
        }
        .label {
            text-align: center;
        }
        .image-container {
            width: 70%;
        }
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            line-height: 1.6;
        }
        header {
            background-color: #333;
            color: #fff;
            padding: 20px;
            text-align: center;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        .image {
            width: 100%;
            margin-bottom: -10px;
        }
        footer {
            background-color: #333;
            color: #fff;
            text-align: center;
            padding: 10px 0;
            position: fixed;
            bottom: 0;
            width: 100%;
        }
        h1, h2, h3, h4, h5, h6 {
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 20px;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
        }
    </style>
</head>
<body>
    <header>
        <h1>CS 184 Homework 4: ClothSim</h1>
        <h2> 
Tanush Talati </h2>
    </header>
    
    <div class="container">
        <h2>Overview</h2>

	<p>
	In this assignment, I implemented a real-time cloth simulator, which relied on a spring-mass based system to physically simulate the movement of physical objects such as cloth. The assignment was split into five parts.
	</p>

	<p>The first part required us to actually build out the grid of springs and masses that represent the cloth. This meant connecting neighboring masses with springs to represent shearing, structural, and bending constraints. Such connections are meant to help get realism into the cloth movement. 
	</p>

	<p>
	In the second part, the structure of connections that were formed was leveraged to actually implement the machinery that would determine the location of the different point masses at different time periods. In other words, it dealt with implementing the simulation component. To do this, first I had to calculate the total force acting on a particular mass. This would be the sum of all the different enabled constraint forces acting on the spring. Next we had to utilize verlet integration, a method to approximate dynamics governed by differential equations to deduce the location and velocity of the point mass at the next time step. Since this method of simulation is unstable in nature, the final step involved bounding the distance of a point mass away from its rest position, which was simply done by checking if it was more that 10% away from its rest position and if it was, we would manually adjust the position to be at the threshold mark.
	</p>
    <p>
	    The third part helped implement a collision detection and handling system. Basically the second part gave a working simulator when only one object existed in the world but with multiple objects, we need to make sure that objects do not go through each other and hence need to detect collisions, because if they occur we can adjust the location of the mass to stay above the collided surface. We only dealt with collisions against two different objects: spheres and planes. The only difference between the two was the process in determining if a collision occurred due to the different geometry of the two surfaces. But after that, if a collision occurred, in both cases a correction vector, allowing the object to stay slightly above the collided point was applied and the new position would be this position scaled by 1 - frictional force.
    </p>
    
    <p>
  The fourth part dealt with self-collisions. This would allow the simulation to exhibit complex geometry such as folding on itself when the cloth is dropped for instance. This was implemented by first creating a hashmap where all masses within a rectangular-prism volume would get hashed into the same key and the value would be a list of the objects in the same volume. Once the hashing was done and all the point masses were placed in their respective arrays, we would compare all the pointmasses inside the respective arrays. If two were within some threshold distance, (2 * thickness), a correction vector would be applied to the two point masses to get them at this threshold distance apart (creating spacing). Due to the possibility of multiple masses being this close, the final correction would just be the average of all the corrections on the point mass. 
    </p>

<p>
The last part was a bit different, it had us implement shaders, a quick way to introduce and implement shading schemes that is relatively computationally cheap. Multiple shaders were implemented. First we started with the basic diffuse shading, where light is reflected equally in all directions. Then, more complex versions were implemented, namely the blinn-phong shading model, texture mapping, displacement and bump-mapping, and environment mapped reflections.
</p>
	    
        <section>
            <h3>Part 1: Masses and Springs</h3>
            
            
            <p>In this part the grid of point masses and the springs that interconnect the various point masses was implemented. This spring-mass representation of the cloth allows us to simulate physics that is used to approximate and simulate realistic cloth movement. The cloth was parameterized by num_width_points and num_height_points, representing the number of masses along the width and height of the cloth respectively. The third dimension was either set to 1 or a random number between -1/1000 and 1/1000 depending on the plane the cloth existed in. Furthermore if a cloth point mass was pinned, hence it would not be moving, that was set as well with a boolean flag.           
            </p>

		<p>Once the grid of point masses was constructed, springs defining the interconnections between the point masses were created. There were three types of spring, representing different constraints: structural, shearing, and bending. Depending on the type of constraint, the spring connected different point masses according to how it was detailed out the spec. Once these mainly bookmarking implementations were complete, a mesh of connections could be seen. These meshes are shown below.
            </p>

		<p>Below is the cloth wireframe showing all the connections both bending and steady behavior.        
            </p>

	    <div class='im-container'>
                <div>
                <div class="label"> Grid-View </div>
                <img class="image-container" src="grid.png" alt="iter0">
                </div>
                <div>  
                <div class="label"> Showing the bending </div>    
                <img class="image-container" src="bending.png" alt="iter1">
                </div>
            </div>

	<p class="caption">Showing the grid view with all three constraints, representing working connection of point-masses using springs.
</p>
<p class="left">
		Now I just show some of the constraints individually.
	</p>

		 <div class='im-container'>
                <div>
                <div class="label"> All Three Constraints </div>
                <img class="image-container" src="three.png" alt="iter0">
                </div>
                <div>  
                <div class="label">Only Shearing Constraints </div>    
                <img class="image-container" src="shearing.png" alt="iter1">
                </div>
		 <div> 
		<div class="label">No Shearing (Bending and Structural) </div>    
                <img class="image-container" src="noshearing.png" alt="iter1">
                </div>
            </div>
			<p class="caption">Showing the connections when turning off some contraints the the view.
</p>
        </section>
        
        <section>
            <h3>Part 2: Simulation via Numerical Integration </h3>
            <p> This section enabled actual cloth simulation. Basically the positions at the next time step, calculated by taking into account the forces exerted on each of the point-masses at the current time-step were calculated using verlet integration. Specifically since the system consists of a lot of interconnected springs, each point mass would have forces being exerted on it by these springs, which can be found out through Hookeâ€™s law. Then applying the rules of dynamics, we know acceleration, mass, and force are related by F = ma, allowing us to find the acceleration and its direction by dividing the force by the mass of the point. Then we can use the equations given my verlet integration to find the new point location of the mass. Doing this point-mass location calculation for all of the pointmasses would help move the grid and give the new position of the cloth. Essentially the new position was calculated as follow x_new = x_old + v_curr * time + a_curr * time^2. And v_curr * time was simply estimated as x_curr - x_old. The exact quantity of time is also dependent on the number of simulation steps per frame and the number of frames per second. Finally since this method of approximation is not stable, we physically bounded the values x could take on. Specifically x could only be at most 10% off its rest position. This would make clothes act more realistically as we know usually it does not move out of place by a large amount.  
	    </p>

		<p>Below are photos showing a working implementation of the cloth simulation, manipulating some of the variables that control the dynamics. 
		</p>

	<div class='im-container'>
                <div>
                <div class="label"> No change default </div>
                <img class="image-container" src="default.png" alt="iter0">
                </div>
            </div> 

		<p class='left'>
		First we change k_s.	
		</p>
       
		<div class='im-container'>
                <div>
                <div class="label"> k_s = 100 N/m </div>
                <img class="image-container" src="100.png" alt="iter0">
                </div>
                <div>  
                <div class="label"> k_s = 10,000 N/m </div>    
                <img class="image-container" src="10000.png" alt="iter1">
                </div>
		<div>  
                <div class="label"> k_s = 100,000 N/m </div>    
                <img class="image-container" src="100000.png" alt="iter2">
                </div>
            </div> 

	<p class="caption">Varying the spring constant value.
</p>

	<p class="left">In comparing the images it is clear that increasing k_s lowers the elasticity of the cloth. Specifically we see the cloth has less of a bend with higher values of k_s. Which makes sense since the force being exerted downward on the cloth does not change but since we have higher k_s, our acceleration downward and hence our displacement downward later on will decrease. In summary a lower k_s value indicates higher cloth elasticity and higher displacement when the same force is applied.
</p>

<p>Now we change density</p>	
			
<div class='im-container'>
                <div>
                <div class="label"> d = 1 g/cm^2 </div>
                <img class="image-container" src="d1.png" alt="iter0">
                </div>
                <div>  
                <div class="label"> d = 15 g/cm^2 </div>    
                <img class="image-container" src="d15.png" alt="iter1">
                </div>
		<div>  
                <div class="label"> d = 1500 g/cm^2 </div>    
                <img class="image-container" src="d1500.png" alt="iter2">
                </div>
            </div> 

	<p class="caption">Varying the density value.
</p>

	
<p class='left'>We notice that reducing the density reduces the bending effect on the cloth. This is expected and explained again using the relationship of F = ma. Specifically a lower density means that each point mass also has a reduced mass. Now, the external force, in this case gravity remains the same so if we have a reduced mass and the same acceleration, our force itself has been reduced. Since the springsâ€™ physical properties have not been changed, they will displace less compared to before, explaining the lower levels of bending with reduced density. </p>

<p>Now we change damping value</p>	
			
<div class='im-container'>
                <div>
                <div class="label"> damp = 0%</div>
                <img class="image-container" src="0damp.png" alt="iter0">
                </div>
                <div>  
                <div class="label"> damp = .01% </div>    
                <img class="image-container" src="damp.01.png" alt="iter1">
                </div>
		<div>  
                <div class="label"> damp = 1% </div>    
                <img class="image-container" src="1damp.png" alt="iter2">
                </div>
            </div> 

	<p class="caption">Varying the damp percent. Notice how in the first picture with no damping we never reach a steady state due to infinite oscillation. On the opposite end, the last picture with 1% damping, the photo is taken mid flight of the cloth before it reaches to its final resting position. This was to show the slowness with which it reaches the bottom. Similarly the middle photo there is a bit of backward oscillation before reaching the rest state, which is not present in the last photo.
</p>

	<p class='left'>Damping is basically an external factor that we add to simulate energy loss through a variety of physical means for instance friction. When comparing the different simulations on different damping parameters, it was clear that higher damping rates lead to the cloth reaching its steady state position much faster. It also leads to less oscillations before reaching steady state, which makes sense as our forces zero-out much quicker with damping. On the other extreme, having no damping lead to no steady-state being reached; the cloth would continue infinitely moving. With higher damping the cloth also took longer to fall down, which also makes sense since we need to wait for more iterations of fresh gravitational force to move downward. </p>

	<p>Now I show pinned4.json at its default steady state.
</p>	
			
<div class='im-container'>
                <div>
                <div class="label"> Wireframe </div>
                <img class="image-container" src="pinned4wire.png" alt="iter0">
                </div>
                <div>  
                <div class="label"> Normal Shading </div>    
                <img class="image-container" src="pinned4.png" alt="iter1">
                </div>
            </div> 

	<p class="caption">Showing pinned4.json in resting state.
</p>


        </section>

        <section>
            <h3>Part 3: Handling collisions with Other Objects</h3>
		<p>In this part, external collisions were handled, allowing objects to be placed on top of each other and more accurate simulation. The first step in determining whether a collision took place or not is determining if the point-masses ever intersected with the geometry in question. Two intersection tests were implemented, namely intersection against a sphere and intersection with a plane. To implement intersection with a sphere, we just had to check if the point massâ€™s current position was inside the sphere, so that would mean that the mass collides with the sphere. The plane is a bit more tricky; we need to check if the new position and the last positions of the point mass are on different sides of the plane. If so, that would imply a collision occurred. Once the collision determination has taken place, we need to correctly adjust the position to prevent clipping and make sure that objects are on top of each other and do not go through. This is just done by finding a correction vector that would take the point massâ€™s location and put it above the surface and not through it and then applying a damping frictional scaling correction of 1-f to that vector. Adding the correction to the last position of the point mass would give the corrected new position for the point-mass, helping us properly implement collision detection and correction.
		</p>
		<p>Below I show scenes from the cloth-sphere intersection varying the spring constant.
		</p>

	<div class='im-container'>
                <div>
                <div class="label">k_s = 500 N/m </div>
                <img class="image-container" src="500k.png" alt="iter0">
                </div>
                <div>  
                <div class="label"> k_s = 5,000 N/m </div>    
                <img class="image-container" src="5000k.png" alt="iter1">
                </div>
		<div>	
                <div class="label">k_s = 50,000 N/m </div>    
                <img class="image-container" src="50000k.png" alt="iter2">
                </div>
            </div> 
	<p class="caption">Comparing the different spring constant values on the steady state of cloth-sphere scene.
</p>
		<p class="left">It is clear as the spring constant increases our cloth looks increasingly stiff as it becomes increasingly inelastic. This stiffness manifests in the appearance over the sphere of the cloth not fully resting on the sphere and instead with higher levels of spring constant value the bottom of the cloth rests higher. This makes sense consider paper, if we rest it on top of a sphere it would act more stiff and not fully take on the ball-like shape. On the other hand if we took a more foldable material like cloth for instance, it could be modeled with lower spring constant value and would more nicely take on the shape of the cloth. </p>

		<p class="left"> Below is the cloth-plane collision scene, helping show the effective implementation of such collision detection. </p>
	
	<div class='im-container'>
                <div>
                <div class="label">Cloth-Plane Intersection </div>
                <img class="image-container" src="planeint.png" alt="flatshading">
                </div>
            </div>
	<p class="caption">The lighter green represents the cloth, which rests on top of the plane, which is colored in the darker green.
</p>
	
        </section>

        <section>
            <h3>Part 4: Global Illumination</h3>

<p>In this task global illumination was implemented, namely the one bounce lighting from the previous part was extended to an arbitrary amount of bounces. The direct illumination part is the same as the zero_bounce so that just gets added, but the indirect illumination can take into account light that arrives at an intersection points after up to N bounces. Some bookkeeping that needed to be done is to first update the driver function est_radiance_global_illumination to return the sum of the zeroth and the at_least_one function call instead of one. Now we edit the at_least_one function to implement the up to N bounce functionality. To do this we make use of the depth of the ray. If the depth of the ray is 1 then we simply only return the 1-bounce lighting estimate. Otherwise we have space for more bounces. In this case we want to recurse and add to our 1-bounce estimate any downstream lighting that we received (because we want to get the total, if isAccumulate is off we just return the tail call / final recursive callâ€™s calculation of the lighting which will allow us to only showcase the lighting at the Nth layer of bounce). To recurse we sample a bouncing ray from the intersection point and similar to before we see if that ray hits any other point on the world if it does then we find the lighting reflected from it using the same recursive call to this at_least_one_function. Before doing the recursive call though, we must make sure to decrease the depth of our ray by one to make sure we have a base case. The recursive call will guarantee to return us the total light accumulated from downstream bounces. We simply add that to our direct 1-bounce estimate and that is the total light we return. Similar to before when we sample the downstream bounces, we must adjust the weights by dividing by the pdf to make sure the sample does not become biased. The accumulating light estimate uses the same formula as the previous part. As it is pretty clear, the only major edit is having a recursive function and updating the driver function to call the recursive version of the function instead of just the one_bounce version. </p>

<p>The last part that I had to implement in this task was having global illumination with Russian roulette. The motivation being that having some constant for the number of bounces might in itself introduce sampling bias. To mitigate that we can simply make the number of bounces also non-deterministic. In particular at every bounce (past the first) there is a small chance that we will not sample that bounce. This way we do not have a biased stopping point for light and on average if the termination probability is around 0.3 like suggested we get around 1 + 3.3 bounces.  We can also further configure the maximum depth if we do not want for some reason to go above some specified depth (similar to the configuration in the adaptive sample). Russian roulette capability was added into the existing at_least_one_bounce function by just setting a boolean flag called recur, which would be true if the coin toss was a head (or if this is our first bounce anyway which we want to take if we have set indirect illumination to on). After which the body of the function is the same as before expect we also need to divide by the pdf of the coin toss being true to not prevent bias when we are accumulating our lighting estimate. If we want an absolute maximum stopping point then we can keep the logic from before having the base-case being hit when our running depth counts that we reduce with each recursive call hits 1.</p>

<p>Here I show some images of global illumination working on various scenes</p>
		<div class='im-container'>
                <div>
                <div class="label"> Spheres </div>
                <img class="image-container" src="1024_gl_sphere.png" alt="before">
                </div>
                <div>  
                <div class="label"> Blob </div>    
                <img class="image-container" src="1024_gl_blob.png" alt="after1">
                </div>
		<div>  
		<div>  
                <div class="label"> Bunny </div>    
                <img class="image-container" src="1024_gl_bunny.png" alt="after2">
                </div>
		<div> 
		<div>  
                <div class="label"> Dragon </div>    
                <img class="image-container" src="1024_gl_dragon.png" alt="after2">
                </div>
		<div> 
            </div>
		<p class="caption">Working global illumination. Pictures rendered with samples per pixel being 1024. </p>

<p class="left">The next set of pictures compare scenes with only direct lighting and then showing the effects of only indirect lighting.</p>

	 <div class='im-container'>
                <div>
                <div class="label"> Direct Lighting on Bunny </div>
                <img class="image-container" src="direct_bunny.png" alt="before">
                </div>
                <div>  
                <div class="label"> Indirect Lighting on Bunny </div>    
                <img class="image-container" src="indirect_bunny.png" alt="after1">
                </div>
		<div>  
		<div>  
                <div class="label"> Direct Lighting on Spheres </div>    
                <img class="image-container" src="direct_balls.png" alt="after2">
                </div>
		<div> 
		<div>  
                <div class="label"> Indirect Lighting on Spheres </div>    
                <img class="image-container" src="indirect_spheres.png" alt="after2">
                </div>
		<div> 
            </div>
	<p class="caption">Note how in the indirect lighting the light source is completely dark, which makes sense since indirect lighting accounts for light generating from bounces on other surfaces. </p>

      <p class="left">Now I show the non-accumulating light at increasing depth of bounces (variable m in the code). </p>

	<div class='im-container'>
                <div>
                <div class="label"> m = 0 </div>
                <img class="image-container" src="no_accum_0_bunny.png" alt="before">
                </div>
                <div>  
                <div class="label"> m = 1 </div>    
                <img class="image-container" src="no_accum_1_bunny.png" alt="after1">
                </div>
		<div>  
		<div>  
                <div class="label"> m = 2 </div>    
                <img class="image-container" src="no_accum_2_bunny.png" alt="after2">
                </div>
		<div> 
		<div>  
                <div class="label"> m = 3 </div>    
                <img class="image-container" src="no_accum_3_bunny.png" alt="after2">
                </div>
		<div> 
		<div>  
                <div class="label"> m = 4 </div>    
                <img class="image-container" src="no_accum_4_bunny.png" alt="after2">
                </div>
		<div> 
		<div>  
                <div class="label"> m = 5 </div>    
                <img class="image-container" src="no_accum_5_bunny.png" alt="after2">
                </div>
		<div> 
            </div>

<p class="caption">Note how there is an apparent decrease in the amount of light affecting the global illumination from subsequent layers. </p>

<p class="left">As mentioned above each subsequent layer we see a decrease in lighting indicating the fact that the effect of that layer on the global light becomes less and less at higher depth levels. We see a particularly sharp drop off between the layer 2 and layer 3, where layer 3 is much darker. This makes sense intuitively as trying to sample light that comes 3 bounces into the camera may not actually hit a light source because there is a good chance one of the rays just hits another part or hits a shadow covering. This probability becomes higher and higher at larger levels, explaining the darkness.
</p>

<p class="left">The set of pictures below show the accumulating global illumination as a function of higher depth levels.
</p>

<div class='im-container'>
                <div>
                <div class="label"> m = 0 </div>
                <img class="image-container" src="accum_0_bunny.png" alt="before">
                </div>
                <div>  
                <div class="label"> m = 1 </div>    
                <img class="image-container" src="accum_1_bunny.png" alt="after1">
                </div>
		<div>  
		<div>  
                <div class="label"> m = 2 </div>    
                <img class="image-container" src="accum_2_bunny.png" alt="after2">
                </div>
		<div> 
		<div>  
                <div class="label"> m = 3 </div>    
                <img class="image-container" src="accum_3_bunny.png" alt="after2">
                </div>
		<div> 
		<div>  
                <div class="label"> m = 4 </div>    
                <img class="image-container" src="accum_4_bunny.png" alt="after2">
                </div>
		<div> 
		<div>  
                <div class="label"> m = 5 </div>    
                <img class="image-container" src="accum_5_bunny.png" alt="after2">
                </div>
		<div> 
            </div> 
			<p class="caption">As with all the photos in this sections we are using 1024 samples per pixel in these renderings. </p>

<p class="left">As seen in these photos if we have higher depths of global illumination our images look brighter, which makes sense because each level is adding some degree of light. However the rate of change of this brightness is also begins to fall off at higher depth levels. We could have predicted this after looking at the previous set of images that showed decreasing light at non-accumulating depth levels.
</p>

			<p class="left">Now I will show the renderings using Russian-Roulette rendering with increasing depth levels.
</p>
	<div class='im-container'>
                <div>
                <div class="label"> m = 0 </div>
                <img class="image-container" src="russian_0_bunny.png" alt="before">
                </div>
                <div>  
                <div class="label"> m = 1 </div>    
                <img class="image-container" src="russian_1_bunny.png" alt="after1">
                </div>
		<div>  
		<div>  
                <div class="label"> m = 2 </div>    
                <img class="image-container" src="russian_2_bunny.png" alt="after2">
                </div>
		<div> 
		<div>  
                <div class="label"> m = 3 </div>    
                <img class="image-container" src="russian_3_bunny.png" alt="after2">
                </div>
		<div> 
		<div>  
                <div class="label"> m = 4 </div>    
                <img class="image-container" src="russian_4_bunny.png" alt="after2">
                </div>
		<div> 
		<div>  
                <div class="label"> m = 100 </div>    
                <img class="image-container" src="russian_100_bunny.png" alt="after2">
                </div>
		<div> 
            </div> 

			<p class="caption">Russian Roulette rendering with increasing max_depth levels. Samples per pixel was still 1024. </p>	
		<p class="left">We see that past around m = 3 the images start looking very similar, especially when comparing m = 4 and m = 100. This makes sense as the parameter used to render these was p = 0.35, which makes our expected bounces around 1 + 3 = 4. The one because we hard code always making one bounce and then apply Russian Roulette.
</p>	

			<p class="left"> Now I am going to compare the renderings when increasing number of pixels per sample while keeping light samples constant at 4.
</p>	
			<div class='im-container'>
                <div>
                <div class="label">  m = 1 </div>
                <img class="image-container" src="sample_1_bunny.png" alt="before">
                </div>
                <div>  
                <div class="label"> m = 2 </div>    
                <img class="image-container" src="sample_2_bunny.png" alt="after1">
                </div>
		<div>  
		<div>  
                <div class="label"> m = 4 </div>    
                <img class="image-container" src="sample_4_bunny.png" alt="after2">
                </div>
		<div> 
		<div>  
                <div class="label"> m = 8 </div>    
                <img class="image-container" src="sample_8_bunny.png" alt="after2">
                </div>
		<div> 
		<div>  
                <div class="label"> m = 16 </div>    
                <img class="image-container" src="sample_16_bunny.png" alt="after2">
                </div>
		<div> 
		<div>  
                <div class="label"> m = 64 </div>    
                <img class="image-container" src="sample_64_bunny.png" alt="after2">
                </div>
		<div> 
		<div>  
                <div class="label"> m = 1024 </div>    
                <img class="image-container" src="sample_1024_bunny.png" alt="after2">
                </div>
		<div> 
            </div> 

			<p class="caption"> Increasing number of samples per pixel while keeping light samples constant. </p>	
			
			<p class="left"> Pretty evidently increasing the number of samples per pixel reduces artifacts that come from noise, our pixel colors become a lot more smooth at higher sample levels and we do not see the dotted-ness that is present at lower sampling levels.
</p>	
			
        </section>

        <section>
             <h3>Part 5: Adaptive Sampling</h3>
            <p> The idea behind adaptive sampling is that we can reduce the noise in our rendered images by only stopping sampling once we are confident about the light estimate at the point. Specifically we implement a 95% confidence interval. In implementing this most of the work is in the outermost function: raytrace_pixel. Here is where we take different ray samples to estimate lighting. Basically the idea is as we are taking these ray samples of lighting we accumulate the mean lighting and the standard deviation of the lighting samples. If the mean * 1.96 *(standard deviation of lighting estimate) / sqrt (number of running samples) represents only a 5% of a deviation from our running estimate mean, then we can claim confident convergence of our mean value and assign that to the pixelâ€™s radiance value. One may notice that having to update the current mean and standard deviation of the average is quite an expensive task if done with every ray sample. To mitigate most probably redundant computation, we define a batch size after which we recalculate the estimates and determine convergence. When the batch size is not met we simply keep a streaming count of the current sum of the light samples and the sum of the samples squared because both of these terms help us calculate the end statistics that will lead to convergence. One can also imagine pathological instances where convergence is very tough especially at high frequency locations. In this case we will resort to an absolute maximum number of samples as being the worst-case endpoint for our lighting estimate. Usually this number is quite large since the chance of reaching it is low as convergence will usually be achieved before. 
</p>
<p>
Attached below are two scenes rendered with adaptive sampling with a maximum sample size of 2048.
</p>
            <div class='im-container'>
                <div>
                <div class="label">Bunny Image </div>
                <img class="image-container" src="adapt_bunny.png" alt="tp">
                </div>
                <div>  
                <div class="label"> Bunny Sampling Rate Image</div>    
                <img class="image-container" src="adapt_bunny_rate.png" alt="tpflip">
                </div>
                <div>
                <div class="label"> Spheres Image </div>
                <img class="image-container" src="adapt_balls.png" alt="tpflips">
                </div>
		    <div>
                <div class="label"> Spheres Sampling Rate Image </div>
                <img class="image-container" src="adapt_balls_rate.png" alt="tpflips">
                </div>
            </div>
            <p class="caption">Showing the rendered scenes using adaptive sampling and the associated sample rates. Notice how high frequency areas tend to have higher sampling rates. These images were rendered using depth of 5 and 1 sample per light.
</p>

		
        </section>

        <section>
             <h3>Part 6: Extra Credit</h3>
		<p>For extra credit I implemented two different changes, both to the BVH to make it run faster.</p>
		<h4>Extra Credit 1: Non-Recursive BVH</h4>

        <p>
	The first optimization I did was to implement the BVH using an iterative approach instead of a recursive one. In order to do this, I used a stack and a while loop. Once the stack was empty, I would know that I had finished making the new nodes and the entire BVH structure was ready. When I needed to make new children nodes (when one of the stopping points had not been met yet like too many primitives existing in the bounding box) I would create the two children nodes and then push them to the stack. This is the same thing as creating two children nodes and recursing on them in DFS order but we save the need to create a new function call and instead can do everything inside the original function. One thing that was particularly tough (maybe this would be obvious for someone more adept with C++) was the fact that the fields in the BVH node structure were defined to be constants and initially I was also placing the updated iterators there but that would not work since one can imagine you need to reupdate the iterators as you make downstream edits. I got around this by adding two extra stacks that held the start and end iterators for each of the on-going nodes. I am still not sure if this is the best way to get around the constants but I can imagine right now it is one place that can be updated to make this even faster.
	</p>
		<p>When noticing the difference between recursive implementation and an iterative on, there was a clear around 18% boost in timing performance, with the rate being more accurate for larger renders. </p>
<h4>Extra Credit 2: Surface Area Heuristic for BVH Node Split</h4>
		<p>The second extra credit item I worked on was applying a different heuristic to the split the primitives into two separate nodes. Specifically, I implemented the surface area based split that was introduced in lecture. Specifically we hypothesize that the hit rate of a node is the proportional to the ratio of the surface area of the outer bounding box to the inner bounding box and hence we want to minimize the hit rate to minimize expected hits and the expected time on intersection. Implementing the surface area heuristic was simple, I just needed to add code that added this score and then I compared the split across 3 different axis, x, y, z. I only split on the mean centroid but one could imagine extending this out to also check each partition between the primitives and seeing if the split was better. But given the meshes we were dealing with, I did not think it would make too much of a difference on the end result given the amount of overhead in preprocessing that split. But the surface area split showed significant improvements over the other split I was previously using. Specifically, having a nicely configured split was showcasing around a drop of 40% in the amount of intersection tests per ray (from around 7 on average to 4). This is significant as that has a huge repercussions in reducing the run times of our tracing times.
		</p>

		
        </section>
			
<!-- 
			<table>
                <thead>
                    <tr>
                        <th>Column 1</th>
                        <th>Column 2</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Data 1</td>
                        <td>Data 2</td>
                    </tr>
                    <tr>
                        <td>Data 3</td>
                        <td>Data 4</td>
                    </tr>
                </tbody>
            </table> -->
        
        <!-- Add more sections as needed -->
        
    </div>
</body>
</html>
