<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CS 184 Homework 1, Tanush Talati</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            line-height: 1.6;
        }
        header {
            background-color: #333;
            color: #fff;
            padding: 20px;
            text-align: center;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        .image {
            width: 100%;
            margin-bottom: 20px;
        }
        footer {
            background-color: #333;
            color: #fff;
            text-align: center;
            padding: 10px 0;
            position: fixed;
            bottom: 0;
            width: 100%;
        }
        h1, h2, h3, h4, h5, h6 {
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 20px;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
        }
    </style>
</head>
<body>
    <header>
        <h1>CS 184 Homework 1: Rasterizer Writeup</h1>
        <h2> Tanush Talati </h2>
    </header>
    
    <div class="container">
        <h2>Overview</h2>
        <p>In this homework I worked on implementing many key components of a rasterizer. </p> 
        <p> First, I implemented rasterizing triangle polygons onto the screen space. The main challenge here was determining whether or not a screen pixel exists inside of the triangle of interest. If it does, then the sample buffer, which contains the pixels (or the set of fragments that will then make up some pixels in the case of supersampling) will be set to the same color as the triangle that is being rasterized. In determining the inside-triangle test, I had to figure out the exact vector-algebra machinery that would output whether a point was inside a triangle given by a set of three vertices. This was probably the most challenging part of the first task as it tested my knowledge of tangent lines, planes, and cross products. The other part I had to figure out was converting the set of given points into a consistent winding order. I decided this would be counterclockwise. In order to do this I had to rely on vector-algebra again, specifically cross-products (which would be positive if the points were in counterclockwise winding order). </p>

        <p>Second, I extended the functionality of the simple triangle rasterizer by implementing super-sampling as a means to introduce anti-aliasing since super-sampling effectively increases sampling frequency. The changes made to the existing rasterize_triangle method were pretty simple; I just had to carefully calculate the position of the super-samples within a pixel using the sampling-rate of our RasterizeImp (done through some drawing and deriving the correct equations). The most challenging part was to edit the rest of the codebase to support sampling. Namely, dynamically changing the size of the sample_buffer depending on the sampling rate as well as resolving the final color to the frame buffer by assigning the color rasterized as a mixture of the samples within a pixel. These components touched a lot of different methods within the codebase that had to be tracked down.</p>

        <p>The next task was to implement transforms. This was quite straightforward, the transformation matrices for rotations, translations, and scaling were already derived before and had to just be written out in code in their corresponding functions.
</p>
        <p>The fourth task was an extension on the rasterization of triangles. This time each vertex had a different color assigned to it, so we were no longer dealing with a single colored polygon. That meant that the sampled points within the triangle that were going to finally go into the frame buffer would need an interpolated mixture of the various colors the triangle was made up of. To implement this, barycentric coordinates were heavily utilized. Namely, barycentric coordinates, made up of the variables alpha, beta, and gamma can be thought of as assigning weights to each vertex of the triangle, having the property that each position relative to the triangle can be represented in barycentric coordinate space instead of x,y,z space. This view gives the nice property of thinking about the barycentric coordinates of points inside the triangle as encoding the weighted sum of each of its vertices. This implied that finding the barycentric coordinate of the point within the triangle being sampled would also allow us to find the weights with which we mix the colors at each of the vertices to assign the final color of the point. It also translates easily to supersampling with no changes necessary. The hardest part was simply determining the barycentric coordinates, which was done by calculating the equation for each of the lines of the triangle and then comparing the ratio of the value evaluated at the point being sampled to the point across from the line (which would be 1). It turns out that instead of finding the equation equating the dot product of the normal of the line with the line anchored at the beginning point of the line in the triangle to the point being sampled would amount to the values mentioned earlier.</p>

        <p>The fifth task had me implement pixel texture sampling. Basically now the coordinates of each of the vertices in the triangles were associated with a texture-sample coordinate, which we would use to determine the color of the various samples of the triangle instead of relying on a color value like we did before. This goes along with the idea of “sampling twice” as mentioned in lecture since we sample points inside the triangle to eventually rasterize and we also sample those corresponding points on the texture space to assign each of the samples a color which is also a sample but from the texture maps. So essentially we needed to find the corresponding texture space coordinate for each sample. This was done through barycentric coordinates since those encode relative positions, so finding the barycentric coordinates and then multiplying those by the coordinates in texture space of the triangle would give the underlying texture coordinate of each point being sampled. Now the texture map is a discrete valued data structure that returns color for each coordinate, however our coordinates are continuous, so essentially to determine a color we need to sample again. Two sampling schemes were implemented, one that just returned the color of the nearest discrete coordinate to the query. And another one that implemented bilinear interpolation, which essentially gave the weighted color average of the closest 4 texture points to the query, weighted by relative distances to those points from the query point. In this way we were able to finally assign a color to the screen sampled coordinate utilizing our texture map.
</p>

        <p>The last task extended the capabilities of our texture mapping system by introducing level sampling. Essentially the issue with solely using pixel sampling is aliasing because movement in screen space could have very different footprints on the texture space; for instance moving by one unit in either the x or the y direction could correspond to multiple units of movement in the texture space, leading to aliasing since our samples of the texture space are changing with extremely high frequency and our overall sampling frequency is too low. This motivates the idea that when the screen space movement footprint is too high for sample space, we want to sample the color that we are assigning from a lower frequency texture map to help anti-alias. This is where level-sampling and mipmaps come into play. Basically mipmaps are the data structure that powers level sampling. Each increasing level of the mipmap contains increasingly filtered versions of the original texture map (we are filtering more and more frequencies of the texture map at higher mipmap levels). Now for each screen space point we sample, we calculate the footprint on the texture map (which is the larger of distance in either the U/V direction we move when we move in X/Y). And the level which we sample at is proportional logarithmically to this distance (which makes sense since each subsequent level halves the number of pixels in each direction, implying the same proportionality). There is a possibility that the logarithm returns a number less than 0 or more than the levels in our mipmap. In that case we sanitize the output and simply query the mipmap at level 0 or the highest value respectively. With the level chosen for each pixel, the mechanism for sampling the map at each level from the previous part still applies, giving us a powerful two-phase texture sampling, leading to extremely nice rendering. Furthermore since the level returned is a continuous value, the level itself can be determined through a bilinear interpolation of the mixture of the color returned from the two closest levels to not have drastic color changes, or we can just use nearest neighbors. Clearly, implementing level sampling along with pixel sampling greatly increased the number of options available to render an image. 
</p>
        
        </p>
        <section>
            <h3>Section 1: Introduction</h3>
            <p>This is the introduction section of your write-up.</p>
            <p>It may contain multiple paragraphs.</p>
            <p>You can <strong>bold</strong> some words for emphasis.</p>
            <ul>
                <li>Bullet point 1</li>
                <li>Bullet point 2</li>
                <li>Bullet point 3</li>
            </ul>
            <img class="image" src="image1.jpg" alt="Image 1">
            <p><i>Caption for image 1 goes here...</i></p>
        </section>
        
        <section>
            <h3>Section 2: Methodology</h3>
            <p>This section explains the methodology used in your project.</p>
            <p>You can include a table to present data:</p>
            <table>
                <thead>
                    <tr>
                        <th>Column 1</th>
                        <th>Column 2</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Data 1</td>
                        <td>Data 2</td>
                    </tr>
                    <tr>
                        <td>Data 3</td>
                        <td>Data 4</td>
                    </tr>
                </tbody>
            </table>
            <img class="image" src="image2.jpg" alt="Image 2">
            <p><i>Caption for image 2 goes here...</i></p>
        </section>
        
        <!-- Add more sections as needed -->
        
    </div>
</body>
</html>
